{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d5a90-f92d-4d52-b00b-cd8391aed3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status: 200\n",
      "url: http://openapi.seoul.go.kr:8088/5164456e63726f6f36396966455849/xml/SpotInfo/1/1/\n",
      "preview: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?><SpotInfo><list_total_count>139</list_total_count><RESULT><CODE>INFO-000</CODE><MESSAGE>정상 처리되었습니다</MESSAGE></RESULT><row><spot_num>C-02</spot_num><spot_nm>월드컵대교</spot_nm><grs80tm_x>189882</grs80tm_x><grs80tm_y>450789</grs80tm_y></row></SpotInfo\n"
     ]
    }
   ],
   "source": [
    "import os, requests\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# notebooks 폴더에서 실행 중이면 루트를 상위로\n",
    "ROOT = Path.cwd().resolve()\n",
    "if ROOT.name.lower() == \"notebooks\":\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "# .env 로드\n",
    "load_dotenv(ROOT / \".env\")\n",
    "\n",
    "# .env에 아래 중 하나로 저장해두면 됨:\n",
    "SEOUL_API_KEY = os.getenv(\"TRAFFIC_KEY\")\n",
    "\n",
    "if not SEOUL_API_KEY:\n",
    "    raise ValueError(\"인증키를 못 찾았어. 프로젝트 루트/.env에 SEOUL_OPENAPI_KEY=... 형태로 넣어줘.\")\n",
    "\n",
    "BASE = \"http://openapi.seoul.go.kr:8088\"\n",
    "\n",
    "# SpotInfo 1건만 테스트 호출 (정상 응답 : XML)\n",
    "url = f\"{BASE}/{SEOUL_API_KEY}/xml/SpotInfo/1/1/\"\n",
    "r = requests.get(url, timeout=20)\n",
    "\n",
    "print(\"status:\", r.status_code)\n",
    "print(\"url:\", url)\n",
    "print(\"preview:\", r.text[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6671839e-3740-4df5-9805-06e4295adbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved: C:\\Users\\A\\OneDrive\\바탕 화면\\seoul-dimming-system\\data\\raw\\traffic\\spotinfo.csv\n",
      "shape: (139, 4)\n",
      "columns: ['spot_num', 'spot_nm', 'grs80tm_x', 'grs80tm_y']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spot_num</th>\n",
       "      <th>spot_nm</th>\n",
       "      <th>grs80tm_x</th>\n",
       "      <th>grs80tm_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-01</td>\n",
       "      <td>성산로(금화터널)</td>\n",
       "      <td>195489</td>\n",
       "      <td>452136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-02</td>\n",
       "      <td>사직로(사직터널)</td>\n",
       "      <td>196756.776106</td>\n",
       "      <td>452546.638644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-03</td>\n",
       "      <td>자하문로(자하문터널)</td>\n",
       "      <td>197216.855046</td>\n",
       "      <td>454350.990432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-04</td>\n",
       "      <td>대사관로(삼청터널)</td>\n",
       "      <td>198648.893154</td>\n",
       "      <td>455200.108465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-05</td>\n",
       "      <td>율곡로(안국역)</td>\n",
       "      <td>198645.671347</td>\n",
       "      <td>452937.216603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  spot_num      spot_nm      grs80tm_x      grs80tm_y\n",
       "0     A-01    성산로(금화터널)         195489         452136\n",
       "1     A-02    사직로(사직터널)  196756.776106  452546.638644\n",
       "2     A-03  자하문로(자하문터널)  197216.855046  454350.990432\n",
       "3     A-04   대사관로(삼청터널)  198648.893154  455200.108465\n",
       "4     A-05     율곡로(안국역)  198645.671347  452937.216603"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "RAW_DIR = ROOT / \"data\" / \"raw\" / \"traffic\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_RAW_SPOTS = RAW_DIR / \"spotinfo.csv\"\n",
    "\n",
    "def xml_rows(xml_text: str):\n",
    "    root = ET.fromstring(xml_text)\n",
    "    rows = root.findall(\".//row\")\n",
    "    out = []\n",
    "    for row in rows:\n",
    "        d = {}\n",
    "        for ch in list(row):\n",
    "            d[ch.tag] = (ch.text.strip() if ch.text else None)\n",
    "        out.append(d)\n",
    "    return out\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "all_rows = []\n",
    "start = 1\n",
    "step = 1000\n",
    "\n",
    "while True:\n",
    "    url = f\"{BASE}/{SEOUL_API_KEY}/xml/SpotInfo/{start}/{start+step-1}/\"\n",
    "    r = session.get(url, timeout=30)\n",
    "    if r.status_code != 200:\n",
    "        raise RuntimeError(f\"SpotInfo 호출 실패: HTTP {r.status_code}\\n{r.text[:300]}\\nURL={url}\")\n",
    "\n",
    "    rows = xml_rows(r.text)\n",
    "    if not rows:\n",
    "        break\n",
    "\n",
    "    all_rows.extend(rows)\n",
    "\n",
    "    # 마지막 페이지면 종료\n",
    "    if len(rows) < step:\n",
    "        break\n",
    "\n",
    "    start += step\n",
    "    time.sleep(0.2)  # 호출 텀(너무 빠르면 막힐 수 있어서)\n",
    "\n",
    "spots = pd.DataFrame(all_rows)\n",
    "spots.columns = [c.lower() for c in spots.columns]\n",
    "\n",
    "spots.to_csv(OUT_RAW_SPOTS, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ saved:\", OUT_RAW_SPOTS)\n",
    "print(\"shape:\", spots.shape)\n",
    "print(\"columns:\", spots.columns.tolist())\n",
    "spots.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cec8846-052f-4ee5-b8fd-d05a0df2c155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPOT_COL: spot_num\n",
      "spots count: 139\n",
      "sample: ['A-01', 'A-02', 'A-03', 'A-04', 'A-05', 'A-06', 'A-07', 'A-08', 'A-09', 'A-10']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "spots_path = RAW_DIR / \"spotinfo.csv\"\n",
    "spots = pd.read_csv(spots_path)\n",
    "spots.columns = [c.lower() for c in spots.columns]\n",
    "\n",
    "# 지점번호 컬럼 자동 탐지\n",
    "spot_id_candidates = [c for c in spots.columns if c in [\"spot_num\", \"spotnum\", \"spot_no\", \"spotid\"]]\n",
    "if not spot_id_candidates:\n",
    "    raise KeyError(f\"SpotInfo에서 지점번호 컬럼을 못 찾았어. spots 컬럼: {list(spots.columns)}\")\n",
    "\n",
    "SPOT_COL = spot_id_candidates[0]\n",
    "spot_list = spots[SPOT_COL].astype(str).dropna().unique().tolist()\n",
    "\n",
    "print(\"SPOT_COL:\", SPOT_COL)\n",
    "print(\"spots count:\", len(spot_list))\n",
    "print(\"sample:\", spot_list[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952db26a-8d30-4065-8b36-668fc3944854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 10/139 (records=153, fail=0)\n",
      "progress: 20/139 (records=306, fail=0)\n",
      "progress: 30/139 (records=420, fail=0)\n",
      "progress: 40/139 (records=699, fail=0)\n",
      "progress: 50/139 (records=837, fail=0)\n",
      "progress: 60/139 (records=1053, fail=0)\n",
      "progress: 70/139 (records=1239, fail=0)\n",
      "progress: 80/139 (records=1437, fail=0)\n",
      "progress: 90/139 (records=1593, fail=0)\n",
      "progress: 100/139 (records=1782, fail=0)\n",
      "progress: 110/139 (records=1959, fail=0)\n",
      "progress: 120/139 (records=2169, fail=0)\n",
      "progress: 130/139 (records=2397, fail=0)\n",
      "✅ saved: C:\\Users\\A\\OneDrive\\바탕 화면\\seoul-dimming-system\\data\\raw\\traffic\\volinfo_hourly_raw.csv\n",
      "raw shape: (2553, 8)\n",
      "fail count: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spot_num</th>\n",
       "      <th>ymd</th>\n",
       "      <th>hh</th>\n",
       "      <th>io_type</th>\n",
       "      <th>lane_num</th>\n",
       "      <th>vol</th>\n",
       "      <th>spot</th>\n",
       "      <th>yyyymmdd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-01</td>\n",
       "      <td>20250115</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>A-01</td>\n",
       "      <td>20250115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-01</td>\n",
       "      <td>20250115</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "      <td>A-01</td>\n",
       "      <td>20250115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-01</td>\n",
       "      <td>20250115</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>261</td>\n",
       "      <td>A-01</td>\n",
       "      <td>20250115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-01</td>\n",
       "      <td>20250115</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>A-01</td>\n",
       "      <td>20250115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-01</td>\n",
       "      <td>20250115</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>A-01</td>\n",
       "      <td>20250115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  spot_num       ymd  hh io_type lane_num  vol  spot  yyyymmdd\n",
       "0     A-01  20250115  01       1        1  165  A-01  20250115\n",
       "1     A-01  20250115  01       1        2  142  A-01  20250115\n",
       "2     A-01  20250115  01       2        1  261  A-01  20250115\n",
       "3     A-01  20250115  01       2        2  169  A-01  20250115\n",
       "4     A-01  20250115  02       1        1   87  A-01  20250115"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "OUT_RAW_HOURLY = RAW_DIR / \"volinfo_hourly_raw.csv\"\n",
    "\n",
    "def xml_rows(xml_text: str):\n",
    "    root = ET.fromstring(xml_text)\n",
    "    rows = root.findall(\".//row\")\n",
    "    out = []\n",
    "    for row in rows:\n",
    "        d = {}\n",
    "        for ch in list(row):\n",
    "            d[ch.tag] = (ch.text.strip() if ch.text else None)\n",
    "        out.append(d)\n",
    "    return out\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "# 날짜/시간 설정\n",
    "DATE = \"20250115\"          # YYYYMMDD\n",
    "HOURS = [\"01\", \"02\", \"03\"] # 01~02, 02~03, 03~04로 쓸 거\n",
    "\n",
    "# 혹시 너무 오래 걸리면 N개만 먼저 (문제 없으면 None 유지)\n",
    "LIMIT_SPOTS = None   # 예: 30 / 아니면 None\n",
    "\n",
    "spots_to_call = spot_list if LIMIT_SPOTS is None else spot_list[:LIMIT_SPOTS]\n",
    "\n",
    "records = []\n",
    "fail = 0\n",
    "\n",
    "for i, spot in enumerate(spots_to_call, 1):\n",
    "    for hh in HOURS:\n",
    "        url = f\"{BASE}/{SEOUL_API_KEY}/xml/VolInfo/1/1000/{spot}/{DATE}/{hh}/\"\n",
    "        r = session.get(url, timeout=30)\n",
    "\n",
    "        if r.status_code != 200:\n",
    "            fail += 1\n",
    "            # 너무 로그 길어지지 않게 요약만\n",
    "            print(f\"❌ fail spot={spot} hh={hh} status={r.status_code}\")\n",
    "            continue\n",
    "\n",
    "        rows = xml_rows(r.text)\n",
    "        for row in rows:\n",
    "            row2 = {k.lower(): v for k, v in row.items()}\n",
    "            row2[\"spot\"] = str(spot)\n",
    "            row2[\"yyyymmdd\"] = DATE\n",
    "            row2[\"hh\"] = hh\n",
    "            records.append(row2)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"progress: {i}/{len(spots_to_call)} (records={len(records)}, fail={fail})\")\n",
    "        time.sleep(0.2)  # 호출 텀\n",
    "\n",
    "raw = pd.DataFrame(records)\n",
    "raw.to_csv(OUT_RAW_HOURLY, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ saved:\", OUT_RAW_HOURLY)\n",
    "print(\"raw shape:\", raw.shape)\n",
    "print(\"fail count:\", fail)\n",
    "raw.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4798e-91b3-4317-9c3d-5092f9bcd460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ VOL_COL: vol\n",
      "✅ saved: C:\\Users\\A\\OneDrive\\바탕 화면\\seoul-dimming-system\\data\\raw\\traffic\\volinfo_spot_traffic_3cols.csv\n",
      "wide shape: (130, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>hh</th>\n",
       "      <th>spot</th>\n",
       "      <th>yyyymmdd</th>\n",
       "      <th>traffic_01_02</th>\n",
       "      <th>traffic_02_03</th>\n",
       "      <th>traffic_03_04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-01</td>\n",
       "      <td>20250115</td>\n",
       "      <td>737</td>\n",
       "      <td>566</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-02</td>\n",
       "      <td>20250115</td>\n",
       "      <td>721</td>\n",
       "      <td>535</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-03</td>\n",
       "      <td>20250115</td>\n",
       "      <td>245</td>\n",
       "      <td>157</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-04</td>\n",
       "      <td>20250115</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-05</td>\n",
       "      <td>20250115</td>\n",
       "      <td>858</td>\n",
       "      <td>636</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A-06</td>\n",
       "      <td>20250115</td>\n",
       "      <td>768</td>\n",
       "      <td>572</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A-07</td>\n",
       "      <td>20250115</td>\n",
       "      <td>576</td>\n",
       "      <td>417</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A-08</td>\n",
       "      <td>20250115</td>\n",
       "      <td>1196</td>\n",
       "      <td>969</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A-09</td>\n",
       "      <td>20250115</td>\n",
       "      <td>982</td>\n",
       "      <td>728</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A-10</td>\n",
       "      <td>20250115</td>\n",
       "      <td>636</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "hh  spot  yyyymmdd  traffic_01_02  traffic_02_03  traffic_03_04\n",
       "0   A-01  20250115            737            566            465\n",
       "1   A-02  20250115            721            535            469\n",
       "2   A-03  20250115            245            157            133\n",
       "3   A-04  20250115              0              1              0\n",
       "4   A-05  20250115            858            636            451\n",
       "5   A-06  20250115            768            572            467\n",
       "6   A-07  20250115            576            417            355\n",
       "7   A-08  20250115           1196            969            865\n",
       "8   A-09  20250115            982            728            681\n",
       "9   A-10  20250115            636            435            435"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "RAW_HOURLY = RAW_DIR / \"volinfo_hourly_raw.csv\"\n",
    "raw = pd.read_csv(RAW_HOURLY)\n",
    "raw.columns = [c.lower() for c in raw.columns]\n",
    "\n",
    "# 교통량 값 컬럼 자동 탐지\n",
    "vol_candidates = [c for c in raw.columns if c in [\"vol\", \"volume\", \"traffic\", \"trfvlm\", \"traffic_volume\"]]\n",
    "if not vol_candidates:\n",
    "    raise KeyError(f\"교통량 값 컬럼을 못 찾았어. raw 컬럼: {list(raw.columns)}\")\n",
    "VOL_COL = vol_candidates[0]\n",
    "\n",
    "# 타입 정리\n",
    "raw[\"spot\"] = raw[\"spot\"].astype(str)\n",
    "raw[\"hh\"] = raw[\"hh\"].astype(str).str.zfill(2)\n",
    "raw[VOL_COL] = pd.to_numeric(raw[VOL_COL], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# 같은 spot+hh에 여러 row가 있을 수 있어서 안전하게 합으로 정리\n",
    "spot_hh = (\n",
    "    raw.groupby([\"spot\", \"yyyymmdd\", \"hh\"], as_index=False)[VOL_COL]\n",
    "       .sum()\n",
    ")\n",
    "\n",
    "# 피벗: spot 행, hh 열\n",
    "wide = spot_hh.pivot(index=[\"spot\",\"yyyymmdd\"], columns=\"hh\", values=VOL_COL).fillna(0).reset_index()\n",
    "\n",
    "# 컬럼명\n",
    "rename_map = {\n",
    "    \"01\": \"traffic_01_02\",\n",
    "    \"02\": \"traffic_02_03\",\n",
    "    \"03\": \"traffic_03_04\"\n",
    "}\n",
    "for hh, newc in rename_map.items():\n",
    "    if hh in wide.columns:\n",
    "        wide.rename(columns={hh: newc}, inplace=True)\n",
    "    else:\n",
    "        wide[newc] = 0\n",
    "\n",
    "OUT_SPOT_WIDE = RAW_DIR / \"volinfo_spot_traffic_3cols.csv\"\n",
    "wide.to_csv(OUT_SPOT_WIDE, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ VOL_COL:\", VOL_COL)\n",
    "print(\"✅ saved:\", OUT_SPOT_WIDE)\n",
    "print(\"wide shape:\", wide.shape)\n",
    "wide.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598e6c50-a270-4f9e-b162-6e3dd030e19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geojson candidates: 1\n",
      " - seongsu_grid_250m_enriched.geojson\n",
      "\n",
      "best guess: C:\\Users\\A\\OneDrive\\바탕 화면\\seoul-dimming-system\\data\\processed\\seongsu_grid_250m_enriched.geojson score: 12\n",
      "✅ loaded: seongsu_grid_250m_enriched.geojson\n",
      "shape: (109, 5)\n",
      "columns: ['grid_id', 'streetlight_cnt', 'cctv_cnt', 'park_cnt', 'geometry']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_id\n",
       "0        0\n",
       "1        1\n",
       "2        2\n",
       "3        3\n",
       "4        4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "PRO_DIR = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# processed 안 geojson 후보 싹 찾기\n",
    "cands = sorted(PRO_DIR.glob(\"*.geojson\"))\n",
    "\n",
    "print(\"geojson candidates:\", len(cands))\n",
    "for p in cands[:30]:\n",
    "    print(\" -\", p.name)\n",
    "\n",
    "# 성수/250/grid 키워드로 우선순위 탐색\n",
    "def score(name: str):\n",
    "    n = name.lower()\n",
    "    s = 0\n",
    "    if \"seongsu\" in n: s += 5\n",
    "    if \"sungsu\" in n:  s += 4\n",
    "    if \"250\" in n:     s += 4\n",
    "    if \"grid\" in n:    s += 3\n",
    "    return s\n",
    "\n",
    "best = None\n",
    "best_score = -1\n",
    "for p in cands:\n",
    "    sc = score(p.name)\n",
    "    if sc > best_score:\n",
    "        best_score = sc\n",
    "        best = p\n",
    "\n",
    "print(\"\\nbest guess:\", best, \"score:\", best_score)\n",
    "\n",
    "if best is None or best_score <= 0:\n",
    "    raise FileNotFoundError(\n",
    "        \"processed 폴더에서 성수 250m 격자 geojson 후보를 못 찾았어. \"\n",
    "        \"seongsu_grid_250m.geojson(또는 비슷한 이름) 파일을 data/processed에 넣어줘.\"\n",
    "    )\n",
    "\n",
    "grid = gpd.read_file(best)\n",
    "grid.columns = [c.lower() for c in grid.columns]\n",
    "\n",
    "print(\"✅ loaded:\", best.name)\n",
    "print(\"shape:\", grid.shape)\n",
    "print(\"columns:\", list(grid.columns))\n",
    "\n",
    "# grid_id 유무 체크\n",
    "if \"grid_id\" not in grid.columns:\n",
    "    raise KeyError(f\"격자 파일에 grid_id 컬럼이 없어. 현재 컬럼: {list(grid.columns)}\")\n",
    "\n",
    "grid[[\"grid_id\"]].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ee43f-485f-47a6-aec0-5951df3fe8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATES: 20251201 ~ 20251214 | days: 14\n",
      "spots: 139\n",
      "progress: 10/139 spots | calls 420/5838 | records=1848 | fail=0\n",
      "progress: 20/139 spots | calls 840/5838 | records=4410 | fail=0\n",
      "progress: 30/139 spots | calls 1260/5838 | records=6333 | fail=0\n",
      "progress: 40/139 spots | calls 1680/5838 | records=9747 | fail=0\n",
      "progress: 50/139 spots | calls 2100/5838 | records=12267 | fail=0\n",
      "progress: 60/139 spots | calls 2520/5838 | records=15174 | fail=0\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', ConnectionResetError(10054, '현재 연결은 원격 호스트에 의해 강제로 끊겼습니다', None, 10054, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionResetError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[31mConnectionResetError\u001b[39m: [WinError 10054] 현재 연결은 원격 호스트에 의해 강제로 끊겼습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mProtocolError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\util\\util.py:38\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value.__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[31mProtocolError\u001b[39m: ('Connection aborted.', ConnectionResetError(10054, '현재 연결은 원격 호스트에 의해 강제로 끊겼습니다', None, 10054, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hh \u001b[38;5;129;01min\u001b[39;00m HOURS:\n\u001b[32m     49\u001b[39m     url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSEOUL_API_KEY\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/xml/VolInfo/1/1000/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspot\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhh\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     r = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     done += \u001b[32m1\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m r.status_code != \u001b[32m200\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\adapters.py:682\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    667\u001b[39m     resp = conn.urlopen(\n\u001b[32m    668\u001b[39m         method=request.method,\n\u001b[32m    669\u001b[39m         url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    678\u001b[39m         chunked=chunked,\n\u001b[32m    679\u001b[39m     )\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n\u001b[32m    684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    685\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, ConnectTimeoutError):\n\u001b[32m    686\u001b[39m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[31mConnectionError\u001b[39m: ('Connection aborted.', ConnectionResetError(10054, '현재 연결은 원격 호스트에 의해 강제로 끊겼습니다', None, 10054, None))"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import geopandas as gpd\n",
    "\n",
    "# 기간/시간대\n",
    "DATES = pd.date_range(\"2025-12-01\", \"2025-12-14\", freq=\"D\").strftime(\"%Y%m%d\").tolist()\n",
    "HOURS = [\"01\", \"02\", \"03\"]  # 01~02, 02~03, 03~04\n",
    "\n",
    "OUT_RAW_MULTI = RAW_DIR / \"volinfo_hourly_raw_20251201_1214.csv\"\n",
    "OUT_CSV = PRO_DIR / \"seongsu_grid_traffic_3cols_median_20251201_1214.csv\"\n",
    "OUT_GEOJSON = PRO_DIR / \"seongsu_grid_250m_plus_traffic_3cols_median_20251201_1214.geojson\"\n",
    "\n",
    "print(\"DATES:\", DATES[0], \"~\", DATES[-1], \"| days:\", len(DATES))\n",
    "print(\"spots:\", len(spot_list))\n",
    "\n",
    "# XML -> rows 파서\n",
    "def xml_rows(xml_text: str):\n",
    "    root = ET.fromstring(xml_text)\n",
    "    rows = root.findall(\".//row\")\n",
    "    out = []\n",
    "    for row in rows:\n",
    "        d = {}\n",
    "        for ch in list(row):\n",
    "            d[ch.tag] = (ch.text.strip() if ch.text else None)\n",
    "        out.append(d)\n",
    "    return out\n",
    "\n",
    "# VolInfo 다중 날짜 수집 (raw)\n",
    "session = requests.Session()\n",
    "\n",
    "records = []\n",
    "fail = 0\n",
    "total_calls = len(spot_list) * len(DATES) * len(HOURS)\n",
    "done = 0\n",
    "\n",
    "for i, spot in enumerate(spot_list, 1):\n",
    "    spot = str(spot)\n",
    "    for d in DATES:\n",
    "        for hh in HOURS:\n",
    "            url = f\"{BASE}/{SEOUL_API_KEY}/xml/VolInfo/1/1000/{spot}/{d}/{hh}/\"\n",
    "            r = session.get(url, timeout=30)\n",
    "            done += 1\n",
    "\n",
    "            if r.status_code != 200:\n",
    "                fail += 1\n",
    "                if fail <= 10:\n",
    "                    print(f\"❌ fail spot={spot} date={d} hh={hh} status={r.status_code}\")\n",
    "                continue\n",
    "\n",
    "            rows = xml_rows(r.text)\n",
    "            for row in rows:\n",
    "                row2 = {k.lower(): v for k, v in row.items()}\n",
    "                row2[\"spot\"] = spot\n",
    "                row2[\"yyyymmdd\"] = d\n",
    "                row2[\"hh\"] = hh\n",
    "                records.append(row2)\n",
    "\n",
    "        # 너무 빠르면 막힐 수 있어서 살짝 텀\n",
    "        time.sleep(0.05)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"progress: {i}/{len(spot_list)} spots | calls {done}/{total_calls} | records={len(records)} | fail={fail}\")\n",
    "\n",
    "raw = pd.DataFrame(records)\n",
    "raw.to_csv(OUT_RAW_MULTI, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ saved raw:\", OUT_RAW_MULTI, \"shape:\", raw.shape, \"fail:\", fail)\n",
    "\n",
    "if raw.empty:\n",
    "    raise ValueError(\"raw가 비었어. (키/날짜/spot 형식/호출 제한) 중 하나 문제일 가능성 큼.\")\n",
    "\n",
    "# raw -> spot-day-hh로 합산 -> spot-day wide(3칼럼)\n",
    "raw.columns = [c.lower() for c in raw.columns]\n",
    "\n",
    "vol_candidates = [c for c in raw.columns if c in [\"vol\", \"volume\", \"traffic\", \"trfvlm\", \"traffic_volume\"]]\n",
    "if not vol_candidates:\n",
    "    raise KeyError(f\"교통량 값 컬럼을 못 찾았어. raw 컬럼: {list(raw.columns)}\")\n",
    "VOL_COL = vol_candidates[0]\n",
    "print(\"VOL_COL:\", VOL_COL)\n",
    "\n",
    "raw[VOL_COL] = pd.to_numeric(raw[VOL_COL], errors=\"coerce\").fillna(0)\n",
    "raw[\"spot\"] = raw[\"spot\"].astype(str)\n",
    "raw[\"hh\"] = raw[\"hh\"].astype(str).str.zfill(2)\n",
    "\n",
    "spot_day_hh = (\n",
    "    raw.groupby([\"spot\", \"yyyymmdd\", \"hh\"], as_index=False)[VOL_COL]\n",
    "       .sum()\n",
    ")\n",
    "\n",
    "wide = (\n",
    "    spot_day_hh.pivot(index=[\"spot\", \"yyyymmdd\"], columns=\"hh\", values=VOL_COL)\n",
    "              .fillna(0)\n",
    "              .reset_index()\n",
    ")\n",
    "\n",
    "rename_map = {\"01\": \"traffic_01_02\", \"02\": \"traffic_02_03\", \"03\": \"traffic_03_04\"}\n",
    "for hh, newc in rename_map.items():\n",
    "    if hh in wide.columns:\n",
    "        wide.rename(columns={hh: newc}, inplace=True)\n",
    "    else:\n",
    "        wide[newc] = 0\n",
    "\n",
    "wide = wide[[\"spot\",\"yyyymmdd\",\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].copy()\n",
    "print(\"wide spot-day shape:\", wide.shape)\n",
    "wide.head()\n",
    "\n",
    "# SpotInfo(TM좌표) -> grid_id 매핑 만들기 (5186/5181 자동 시도)\n",
    "spots = pd.read_csv(RAW_DIR / \"spotinfo.csv\")\n",
    "spots.columns = [c.lower() for c in spots.columns]\n",
    "\n",
    "# 데이터\n",
    "SPOT_COL = \"spot_num\"\n",
    "X_COL = \"grs80tm_x\"\n",
    "Y_COL = \"grs80tm_y\"\n",
    "\n",
    "spots[SPOT_COL] = spots[SPOT_COL].astype(str)\n",
    "spots[X_COL] = pd.to_numeric(spots[X_COL], errors=\"coerce\")\n",
    "spots[Y_COL] = pd.to_numeric(spots[Y_COL], errors=\"coerce\")\n",
    "spots = spots.dropna(subset=[X_COL, Y_COL]).copy()\n",
    "\n",
    "if grid.crs is None:\n",
    "    grid = grid.set_crs(\"EPSG:4326\", allow_override=True)\n",
    "\n",
    "candidates = [\"EPSG:5186\", \"EPSG:5181\"]\n",
    "best_joined, best_n, best_epsg = None, -1, None\n",
    "\n",
    "for epsg in candidates:\n",
    "    g_spots = gpd.GeoDataFrame(\n",
    "        spots[[SPOT_COL, X_COL, Y_COL]].copy(),\n",
    "        geometry=gpd.points_from_xy(spots[X_COL], spots[Y_COL]),\n",
    "        crs=epsg\n",
    "    ).to_crs(grid.crs)\n",
    "\n",
    "    joined = gpd.sjoin(g_spots, grid[[\"grid_id\", \"geometry\"]], how=\"inner\", predicate=\"within\")\n",
    "    if len(joined) > best_n:\n",
    "        best_joined, best_n, best_epsg = joined, len(joined), epsg\n",
    "\n",
    "print(\"✅ best spot CRS:\", best_epsg, \"| joined rows:\", best_n)\n",
    "\n",
    "spot_to_grid = best_joined[[SPOT_COL, \"grid_id\"]].drop_duplicates().copy()\n",
    "spot_to_grid.rename(columns={SPOT_COL: \"spot\"}, inplace=True)\n",
    "spot_to_grid[\"spot\"] = spot_to_grid[\"spot\"].astype(str)\n",
    "\n",
    "# spot-day wide + grid_id 붙여서 grid-day 합산\n",
    "tmp = wide.merge(spot_to_grid, on=\"spot\", how=\"left\")\n",
    "print(\"unmapped rows:\", tmp[\"grid_id\"].isna().sum())\n",
    "tmp = tmp.dropna(subset=[\"grid_id\"]).copy()\n",
    "\n",
    "for c in [\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]:\n",
    "    tmp[c] = pd.to_numeric(tmp[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "grid_day = (\n",
    "    tmp.groupby([\"grid_id\",\"yyyymmdd\"], as_index=False)[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]]\n",
    "       .sum()\n",
    ")\n",
    "print(\"grid-day shape:\", grid_day.shape)\n",
    "\n",
    "# 14일 중앙값(median)으로 grid_id 대표값 만들기\n",
    "grid_med = (\n",
    "    grid_day.groupby(\"grid_id\", as_index=False)[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]]\n",
    "            .median()\n",
    ")\n",
    "\n",
    "grid_med.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ saved csv:\", OUT_CSV, \"shape:\", grid_med.shape)\n",
    "\n",
    "# 격자 geojson에도 붙여서 저장\n",
    "grid2 = grid.merge(grid_med, on=\"grid_id\", how=\"left\")\n",
    "for c in [\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]:\n",
    "    grid2[c] = grid2[c].fillna(0)\n",
    "\n",
    "grid2.to_file(OUT_GEOJSON, driver=\"GeoJSON\", encoding=\"utf-8\")\n",
    "print(\"✅ saved geojson:\", OUT_GEOJSON)\n",
    "\n",
    "grid2[[\"grid_id\",\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125a4266-2c36-4b44-85b6-011b01f2300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ resume from existing raw: C:\\Users\\A\\OneDrive\\바탕 화면\\seoul-dimming-system\\data\\raw\\traffic\\volinfo_hourly_raw_20251201_1214.csv | done keys: 3242\n",
      "progress: 10/139 spots | fail=0 | calls=420/5838\n",
      "progress: 20/139 spots | fail=0 | calls=840/5838\n",
      "progress: 30/139 spots | fail=0 | calls=1260/5838\n",
      "progress: 40/139 spots | fail=0 | calls=1680/5838\n",
      "progress: 50/139 spots | fail=0 | calls=2100/5838\n",
      "progress: 60/139 spots | fail=0 | calls=2520/5838\n",
      "progress: 70/139 spots | fail=0 | calls=2940/5838\n",
      "progress: 80/139 spots | fail=0 | calls=3360/5838\n",
      "progress: 90/139 spots | fail=0 | calls=3780/5838\n",
      "💾 flushed rows: total_saved≈5007 | fail=0 | progress calls=4139/5838\n",
      "progress: 100/139 spots | fail=0 | calls=4200/5838\n",
      "progress: 110/139 spots | fail=0 | calls=4620/5838\n",
      "💾 flushed rows: total_saved≈10007 | fail=0 | progress calls=4862/5838\n",
      "progress: 120/139 spots | fail=0 | calls=5040/5838\n",
      "progress: 130/139 spots | fail=0 | calls=5460/5838\n",
      "💾 flushed rows: total_saved≈15007 | fail=0 | progress calls=5483/5838\n",
      "✅ raw saved: C:\\Users\\A\\OneDrive\\바탕 화면\\seoul-dimming-system\\data\\raw\\traffic\\volinfo_hourly_raw_20251201_1214.csv | added rows: 17007 | fail: 0\n",
      "VOL_COL: vol\n",
      "✅ best spot CRS: EPSG:5181 | joined rows: 2\n",
      "✅ saved csv: C:\\Users\\A\\OneDrive\\바탕 화면\\seoul-dimming-system\\data\\processed\\seongsu_grid_traffic_3cols_median_20251201_1214.csv shape: (2, 4)\n",
      "✅ saved geojson: C:\\Users\\A\\OneDrive\\바탕 화면\\seoul-dimming-system\\data\\processed\\seongsu_grid_250m_plus_traffic_3cols_median_20251201_1214.geojson\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>traffic_01_02</th>\n",
       "      <th>traffic_02_03</th>\n",
       "      <th>traffic_03_04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_id  traffic_01_02  traffic_02_03  traffic_03_04\n",
       "0        0            0.0            0.0            0.0\n",
       "1        1            0.0            0.0            0.0\n",
       "2        2            0.0            0.0            0.0\n",
       "3        3            0.0            0.0            0.0\n",
       "4        4            0.0            0.0            0.0\n",
       "5        5            0.0            0.0            0.0\n",
       "6        6            0.0            0.0            0.0\n",
       "7        7            0.0            0.0            0.0\n",
       "8        8            0.0            0.0            0.0\n",
       "9        9            0.0            0.0            0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "DATES = pd.date_range(\"2025-12-01\", \"2025-12-14\", freq=\"D\").strftime(\"%Y%m%d\").tolist()\n",
    "HOURS = [\"01\", \"02\", \"03\"]\n",
    "\n",
    "OUT_RAW_MULTI = RAW_DIR / \"volinfo_hourly_raw_20251201_1214.csv\"\n",
    "OUT_CSV = PRO_DIR / \"seongsu_grid_traffic_3cols_median_20251201_1214.csv\"\n",
    "OUT_GEOJSON = PRO_DIR / \"seongsu_grid_250m_plus_traffic_3cols_median_20251201_1214.geojson\"\n",
    "\n",
    "# XML parser\n",
    "def xml_rows(xml_text: str):\n",
    "    if not xml_text or not str(xml_text).strip():\n",
    "        return []\n",
    "    txt = str(xml_text).strip()\n",
    "    # 에러메시지/HTML/빈값이 섞여 들어오는 경우 방어\n",
    "    if \"<row\" not in txt:\n",
    "        return []\n",
    "    try:\n",
    "        root = ET.fromstring(txt)\n",
    "    except ET.ParseError:\n",
    "        return []\n",
    "    rows = root.findall(\".//row\")\n",
    "    out = []\n",
    "    for row in rows:\n",
    "        d = {}\n",
    "        for ch in list(row):\n",
    "            d[ch.tag] = (ch.text.strip() if ch.text else None)\n",
    "        out.append(d)\n",
    "    return out\n",
    "\n",
    "\n",
    "# safe fetch with retry/backoff\n",
    "session = requests.Session()\n",
    "\n",
    "def safe_get(url, timeout=30, max_retry=10, base_sleep=0.7):\n",
    "    last = None\n",
    "    for k in range(max_retry):\n",
    "        try:\n",
    "            r = session.get(url, timeout=timeout)\n",
    "            if r.status_code == 200:\n",
    "                txt = (r.text or \"\").strip()\n",
    "                # XML이 너무 짧거나 row가 아예 없으면 서버가 헛응답 준 걸로 보고 재시도\n",
    "                if len(txt) < 50:\n",
    "                    raise RuntimeError(\"empty/too short body\")\n",
    "                return r\n",
    "            last = RuntimeError(f\"HTTP {r.status_code}\")\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "        time.sleep(base_sleep * (2 ** min(k, 4)) + random.uniform(0, 0.4))\n",
    "    raise last\n",
    "    if r.status_code == 200:\n",
    "        txt = (r.text or \"\").strip()\n",
    "    if \"<row\" not in txt:\n",
    "        raise RuntimeError(\"no <row> in body\")\n",
    "    return r\n",
    "\n",
    "\n",
    "\n",
    "# resume: already collected keys\n",
    "done_keys = set()\n",
    "if OUT_RAW_MULTI.exists():\n",
    "    prev = pd.read_csv(OUT_RAW_MULTI, usecols=[\"spot\",\"yyyymmdd\",\"hh\"])\n",
    "    prev[\"spot\"] = prev[\"spot\"].astype(str)\n",
    "    prev[\"yyyymmdd\"] = prev[\"yyyymmdd\"].astype(str)\n",
    "    prev[\"hh\"] = prev[\"hh\"].astype(str).str.zfill(2)\n",
    "    done_keys = set(zip(prev[\"spot\"], prev[\"yyyymmdd\"], prev[\"hh\"]))\n",
    "    print(\"✅ resume from existing raw:\", OUT_RAW_MULTI, \"| done keys:\", len(done_keys))\n",
    "else:\n",
    "    print(\"✅ start fresh (no existing raw)\")\n",
    "\n",
    "# main loop\n",
    "records = []\n",
    "fail = 0\n",
    "saved = 0\n",
    "\n",
    "total_calls = len(spot_list) * len(DATES) * len(HOURS)\n",
    "done = 0\n",
    "\n",
    "for i, spot in enumerate(spot_list, 1):\n",
    "    spot = str(spot)\n",
    "    for d in DATES:\n",
    "        for hh in HOURS:\n",
    "            done += 1\n",
    "            key = (spot, d, hh)\n",
    "            if key in done_keys:\n",
    "                continue\n",
    "\n",
    "            url = f\"{BASE}/{SEOUL_API_KEY}/xml/VolInfo/1/1000/{spot}/{d}/{hh}/\"\n",
    "\n",
    "            try:\n",
    "                r = safe_get(url, timeout=30, max_retry=8, base_sleep=0.6)\n",
    "            except Exception:\n",
    "                fail += 1\n",
    "                # 실패가 누적되면 잠깐 쉬어주기\n",
    "                if fail % 10 == 0:\n",
    "                    time.sleep(10)\n",
    "                continue\n",
    "\n",
    "            rows = xml_rows(r.text)\n",
    "            for row in rows:\n",
    "                row2 = {k.lower(): v for k, v in row.items()}\n",
    "                row2[\"spot\"] = spot\n",
    "                row2[\"yyyymmdd\"] = d\n",
    "                row2[\"hh\"] = hh\n",
    "                records.append(row2)\n",
    "\n",
    "            # 요청 간 텀 (너무 빠르면 다시 끊김)\n",
    "            time.sleep(0.12 + random.uniform(0, 0.08))\n",
    "\n",
    "            # ---- flush: 5000행마다 raw에 append 저장 ----\n",
    "            if len(records) >= 5000:\n",
    "                df = pd.DataFrame(records)\n",
    "                mode = \"a\" if OUT_RAW_MULTI.exists() else \"w\"\n",
    "                header = not OUT_RAW_MULTI.exists()\n",
    "                df.to_csv(OUT_RAW_MULTI, mode=mode, header=header, index=False, encoding=\"utf-8-sig\")\n",
    "                saved += len(records)\n",
    "                records = []\n",
    "                print(f\"💾 flushed rows: total_saved≈{saved} | fail={fail} | progress calls={done}/{total_calls}\")\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"progress: {i}/{len(spot_list)} spots | fail={fail} | calls={done}/{total_calls}\")\n",
    "\n",
    "# 마지막 남은 records flush\n",
    "if records:\n",
    "    df = pd.DataFrame(records)\n",
    "    mode = \"a\" if OUT_RAW_MULTI.exists() else \"w\"\n",
    "    header = not OUT_RAW_MULTI.exists()\n",
    "    df.to_csv(OUT_RAW_MULTI, mode=mode, header=header, index=False, encoding=\"utf-8-sig\")\n",
    "    saved += len(records)\n",
    "\n",
    "print(\"✅ raw saved:\", OUT_RAW_MULTI, \"| added rows:\", saved, \"| fail:\", fail)\n",
    "\n",
    "\n",
    "# 이후는 raw -> grid median (이전 셀의 아래 부분 그대로)\n",
    "raw = pd.read_csv(OUT_RAW_MULTI)\n",
    "raw.columns = [c.lower() for c in raw.columns]\n",
    "\n",
    "vol_candidates = [c for c in raw.columns if c in [\"vol\", \"volume\", \"traffic\", \"trfvlm\", \"traffic_volume\"]]\n",
    "if not vol_candidates:\n",
    "    raise KeyError(f\"교통량 값 컬럼을 못 찾았어. raw 컬럼: {list(raw.columns)}\")\n",
    "VOL_COL = vol_candidates[0]\n",
    "print(\"VOL_COL:\", VOL_COL)\n",
    "\n",
    "raw[VOL_COL] = pd.to_numeric(raw[VOL_COL], errors=\"coerce\").fillna(0)\n",
    "raw[\"spot\"] = raw[\"spot\"].astype(str)\n",
    "raw[\"hh\"] = raw[\"hh\"].astype(str).str.zfill(2)\n",
    "\n",
    "spot_day_hh = raw.groupby([\"spot\",\"yyyymmdd\",\"hh\"], as_index=False)[VOL_COL].sum()\n",
    "wide = spot_day_hh.pivot(index=[\"spot\",\"yyyymmdd\"], columns=\"hh\", values=VOL_COL).fillna(0).reset_index()\n",
    "\n",
    "rename_map = {\"01\": \"traffic_01_02\", \"02\": \"traffic_02_03\", \"03\": \"traffic_03_04\"}\n",
    "for hh, newc in rename_map.items():\n",
    "    if hh in wide.columns:\n",
    "        wide.rename(columns={hh: newc}, inplace=True)\n",
    "    else:\n",
    "        wide[newc] = 0\n",
    "\n",
    "wide = wide[[\"spot\",\"yyyymmdd\",\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].copy()\n",
    "\n",
    "# spot->grid 매핑 (TM좌표 5186/5181 자동)\n",
    "import geopandas as gpd\n",
    "\n",
    "spots = pd.read_csv(RAW_DIR / \"spotinfo.csv\")\n",
    "spots.columns = [c.lower() for c in spots.columns]\n",
    "SPOT_COL = \"spot_num\"\n",
    "X_COL = \"grs80tm_x\"\n",
    "Y_COL = \"grs80tm_y\"\n",
    "\n",
    "spots[SPOT_COL] = spots[SPOT_COL].astype(str)\n",
    "spots[X_COL] = pd.to_numeric(spots[X_COL], errors=\"coerce\")\n",
    "spots[Y_COL] = pd.to_numeric(spots[Y_COL], errors=\"coerce\")\n",
    "spots = spots.dropna(subset=[X_COL, Y_COL]).copy()\n",
    "\n",
    "if grid.crs is None:\n",
    "    grid = grid.set_crs(\"EPSG:4326\", allow_override=True)\n",
    "\n",
    "best_joined, best_n, best_epsg = None, -1, None\n",
    "for epsg in [\"EPSG:5186\",\"EPSG:5181\"]:\n",
    "    g_spots = gpd.GeoDataFrame(\n",
    "        spots[[SPOT_COL, X_COL, Y_COL]].copy(),\n",
    "        geometry=gpd.points_from_xy(spots[X_COL], spots[Y_COL]),\n",
    "        crs=epsg\n",
    "    ).to_crs(grid.crs)\n",
    "    joined = gpd.sjoin(g_spots, grid[[\"grid_id\",\"geometry\"]], how=\"inner\", predicate=\"within\")\n",
    "    if len(joined) > best_n:\n",
    "        best_joined, best_n, best_epsg = joined, len(joined), epsg\n",
    "\n",
    "print(\"✅ best spot CRS:\", best_epsg, \"| joined rows:\", best_n)\n",
    "\n",
    "spot_to_grid = best_joined[[SPOT_COL,\"grid_id\"]].drop_duplicates().copy()\n",
    "spot_to_grid.rename(columns={SPOT_COL:\"spot\"}, inplace=True)\n",
    "spot_to_grid[\"spot\"] = spot_to_grid[\"spot\"].astype(str)\n",
    "\n",
    "tmp = wide.merge(spot_to_grid, on=\"spot\", how=\"left\").dropna(subset=[\"grid_id\"]).copy()\n",
    "for c in [\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]:\n",
    "    tmp[c] = pd.to_numeric(tmp[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "grid_day = tmp.groupby([\"grid_id\",\"yyyymmdd\"], as_index=False)[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].sum()\n",
    "grid_med = grid_day.groupby(\"grid_id\", as_index=False)[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].median()\n",
    "\n",
    "grid_med.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ saved csv:\", OUT_CSV, \"shape:\", grid_med.shape)\n",
    "\n",
    "grid2 = grid.merge(grid_med, on=\"grid_id\", how=\"left\")\n",
    "for c in [\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]:\n",
    "    grid2[c] = grid2[c].fillna(0)\n",
    "\n",
    "grid2.to_file(OUT_GEOJSON, driver=\"GeoJSON\", encoding=\"utf-8\")\n",
    "print(\"✅ saved geojson:\", OUT_GEOJSON)\n",
    "\n",
    "grid2[[\"grid_id\",\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf36b67-4808-4c9c-a739-e090c7bb68a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ base: (109, 3)\n",
      "✅ traffic: (2, 4)\n",
      "✅ merged: (109, 6)\n",
      "✅ saved: C:\\Users\\A\\OneDrive\\바탕 화면\\seoul-dimming-system\\data\\processed\\grid_features_base_plus_traffic3cols_20251201_1214.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>traffic_01_02</th>\n",
       "      <th>traffic_02_03</th>\n",
       "      <th>traffic_03_04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  grid_id  traffic_01_02  traffic_02_03  traffic_03_04\n",
       "0       0            0.0            0.0            0.0\n",
       "1       1            0.0            0.0            0.0\n",
       "2       2            0.0            0.0            0.0\n",
       "3       3            0.0            0.0            0.0\n",
       "4       4            0.0            0.0            0.0\n",
       "5       5            0.0            0.0            0.0\n",
       "6       6            0.0            0.0            0.0\n",
       "7       7            0.0            0.0            0.0\n",
       "8       8            0.0            0.0            0.0\n",
       "9       9            0.0            0.0            0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PRO_DIR = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "BASE_FEATURES = PRO_DIR / \"grid_features_base.csv\"\n",
    "TRAFFIC_3COLS = PRO_DIR / \"seongsu_grid_traffic_3cols_median_20251201_1214.csv\"\n",
    "OUT_FINAL     = PRO_DIR / \"grid_features_base_plus_traffic3cols_20251201_1214.csv\"\n",
    "\n",
    "base = pd.read_csv(BASE_FEATURES, dtype={\"grid_id\": str})\n",
    "traffic = pd.read_csv(TRAFFIC_3COLS, dtype={\"grid_id\": str})\n",
    "\n",
    "# grid_id 컬럼 대소문자 통일\n",
    "base.columns = [c if c.lower() != \"grid_id\" else \"grid_id\" for c in base.columns]\n",
    "traffic.columns = [c if c.lower() != \"grid_id\" else \"grid_id\" for c in traffic.columns]\n",
    "\n",
    "# 중복 방어(거의 없겠지만 안전하게)\n",
    "traffic = traffic.groupby(\"grid_id\", as_index=False)[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].mean()\n",
    "\n",
    "merged = base.merge(traffic, on=\"grid_id\", how=\"left\")\n",
    "\n",
    "for c in [\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]:\n",
    "    merged[c] = merged[c].fillna(0)\n",
    "\n",
    "merged.to_csv(OUT_FINAL, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ base:\", base.shape)\n",
    "print(\"✅ traffic:\", traffic.shape)\n",
    "print(\"✅ merged:\", merged.shape)\n",
    "print(\"✅ saved:\", OUT_FINAL)\n",
    "\n",
    "merged[[\"grid_id\",\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e15d54d-4061-41a3-8b14-315f332b8f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traffic head:\n",
      "   grid_id  traffic_01_02  traffic_02_03  traffic_03_04\n",
      "0    10.0         2808.0         2278.0         1958.0\n",
      "1    85.0         2361.0         1926.0         1490.0\n",
      "\n",
      "traffic stats (sum):\n",
      "traffic_01_02    5169.0\n",
      "traffic_02_03    4204.0\n",
      "traffic_03_04    3448.0\n",
      "dtype: float64\n",
      "\n",
      "traffic nonzero rows: 2 / 2\n",
      "\n",
      "base grid_id sample: ['0', '1', '2', '3', '4']\n",
      "traffic grid_id sample: ['10.0', '85.0']\n",
      "\n",
      "intersection count: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PRO_DIR = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "BASE_FEATURES = PRO_DIR / \"grid_features_base.csv\"\n",
    "TRAFFIC_3COLS = PRO_DIR / \"seongsu_grid_traffic_3cols_median_20251201_1214.csv\"\n",
    "\n",
    "base = pd.read_csv(BASE_FEATURES, dtype={\"grid_id\": str})\n",
    "traffic = pd.read_csv(TRAFFIC_3COLS, dtype={\"grid_id\": str})\n",
    "\n",
    "# 컬럼 통일\n",
    "base.columns = [c if c.lower() != \"grid_id\" else \"grid_id\" for c in base.columns]\n",
    "traffic.columns = [c if c.lower() != \"grid_id\" else \"grid_id\" for c in traffic.columns]\n",
    "\n",
    "# 값이 진짜 0뿐인지 확인\n",
    "print(\"traffic head:\\n\", traffic.head())\n",
    "print(\"\\ntraffic stats (sum):\")\n",
    "print(traffic[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].sum())\n",
    "\n",
    "nonzero_rows = (traffic[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].sum(axis=1) > 0).sum()\n",
    "print(\"\\ntraffic nonzero rows:\", nonzero_rows, \"/\", len(traffic))\n",
    "\n",
    "# grid_id 샘플 비교\n",
    "print(\"\\nbase grid_id sample:\", base[\"grid_id\"].astype(str).head(5).tolist())\n",
    "print(\"traffic grid_id sample:\", traffic[\"grid_id\"].astype(str).head(5).tolist())\n",
    "\n",
    "# 교집합 개수 확인(merge가 되는지)\n",
    "base_ids = set(base[\"grid_id\"].astype(str))\n",
    "traffic_ids = set(traffic[\"grid_id\"].astype(str))\n",
    "print(\"\\nintersection count:\", len(base_ids & traffic_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da517cad-b514-4a75-8d17-d9d44a6e9a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection after clean: 2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_gid(s):\n",
    "    s = str(s).strip()\n",
    "    s = re.sub(r\"\\.0$\", \"\", s)   # 123.0 -> 123\n",
    "    return s\n",
    "\n",
    "base[\"grid_id\"] = base[\"grid_id\"].apply(clean_gid)\n",
    "traffic[\"grid_id\"] = traffic[\"grid_id\"].apply(clean_gid)\n",
    "\n",
    "print(\"intersection after clean:\", len(set(base[\"grid_id\"]) & set(traffic[\"grid_id\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4ba13-7c80-44bf-9d6e-fccbb4c310ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:5186 joined_rows= 0\n",
      "EPSG:5181 joined_rows= 2\n",
      "EPSG:5179 joined_rows= 0\n",
      "EPSG:5187 joined_rows= 0\n",
      "EPSG:5183 joined_rows= 0\n",
      "EPSG:5174 joined_rows= 2\n",
      "EPSG:5178 joined_rows= 0\n",
      "\n",
      "✅ BEST EPSG: EPSG:5181 | joined_rows: 2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "매핑이 너무 적게 됐어. 격자 CRS/spot 좌표가 서로 안 맞을 가능성이 큼. joined_rows가 최소 수백은 나와야 정상.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ BEST EPSG:\u001b[39m\u001b[33m\"\u001b[39m, best[\u001b[33m\"\u001b[39m\u001b[33mepsg\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33m| joined_rows:\u001b[39m\u001b[33m\"\u001b[39m, best[\u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best[\u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m] <= \u001b[32m10\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m매핑이 너무 적게 됐어. 격자 CRS/spot 좌표가 서로 안 맞을 가능성이 큼. joined_rows가 최소 수백은 나와야 정상.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     77\u001b[39m spot_to_grid = best[\u001b[33m\"\u001b[39m\u001b[33mjoined\u001b[39m\u001b[33m\"\u001b[39m][[SPOT_COL,\u001b[33m\"\u001b[39m\u001b[33mgrid_id\u001b[39m\u001b[33m\"\u001b[39m]].drop_duplicates().copy()\n\u001b[32m     78\u001b[39m spot_to_grid.rename(columns={SPOT_COL:\u001b[33m\"\u001b[39m\u001b[33mspot\u001b[39m\u001b[33m\"\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: 매핑이 너무 적게 됐어. 격자 CRS/spot 좌표가 서로 안 맞을 가능성이 큼. joined_rows가 최소 수백은 나와야 정상."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "PRO_DIR = ROOT / \"data\" / \"processed\"\n",
    "RAW_DIR = ROOT / \"data\" / \"raw\" / \"traffic\"\n",
    "\n",
    "GRID_PATH = PRO_DIR / \"seongsu_grid_250m_enriched.geojson\"\n",
    "RAW_MULTI = RAW_DIR / \"volinfo_hourly_raw_20251201_1214.csv\"\n",
    "SPOTINFO  = RAW_DIR / \"spotinfo.csv\"\n",
    "\n",
    "OUT_TRAFFIC = PRO_DIR / \"seongsu_grid_traffic_3cols_median_20251201_1214.csv\"\n",
    "\n",
    "grid = gpd.read_file(GRID_PATH)\n",
    "grid.columns = [c.lower() for c in grid.columns]\n",
    "if grid.crs is None:\n",
    "    grid = grid.set_crs(\"EPSG:4326\", allow_override=True)\n",
    "\n",
    "raw = pd.read_csv(RAW_MULTI)\n",
    "raw.columns = [c.lower() for c in raw.columns]\n",
    "\n",
    "# 교통량 값 컬럼 자동탐지\n",
    "vol_candidates = [c for c in raw.columns if c in [\"vol\",\"volume\",\"traffic\",\"trfvlm\",\"traffic_volume\"]]\n",
    "if not vol_candidates:\n",
    "    raise KeyError(f\"교통량 값 컬럼 못 찾음. raw cols={list(raw.columns)}\")\n",
    "VOL_COL = vol_candidates[0]\n",
    "\n",
    "raw[VOL_COL] = pd.to_numeric(raw[VOL_COL], errors=\"coerce\").fillna(0)\n",
    "raw[\"spot\"] = raw[\"spot\"].astype(str)\n",
    "raw[\"hh\"] = raw[\"hh\"].astype(str).str.zfill(2)\n",
    "\n",
    "# spot-day-hh 합산 -> spot-day wide(3칼럼)\n",
    "spot_day_hh = raw.groupby([\"spot\",\"yyyymmdd\",\"hh\"], as_index=False)[VOL_COL].sum()\n",
    "wide = spot_day_hh.pivot(index=[\"spot\",\"yyyymmdd\"], columns=\"hh\", values=VOL_COL).fillna(0).reset_index()\n",
    "\n",
    "rename_map = {\"01\":\"traffic_01_02\",\"02\":\"traffic_02_03\",\"03\":\"traffic_03_04\"}\n",
    "for hh, newc in rename_map.items():\n",
    "    if hh in wide.columns:\n",
    "        wide.rename(columns={hh:newc}, inplace=True)\n",
    "    else:\n",
    "        wide[newc] = 0\n",
    "wide = wide[[\"spot\",\"yyyymmdd\",\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].copy()\n",
    "\n",
    "# SpotInfo (TM)\n",
    "spots = pd.read_csv(SPOTINFO)\n",
    "spots.columns = [c.lower() for c in spots.columns]\n",
    "SPOT_COL = \"spot_num\"\n",
    "X_COL = \"grs80tm_x\"\n",
    "Y_COL = \"grs80tm_y\"\n",
    "\n",
    "spots[SPOT_COL] = spots[SPOT_COL].astype(str)\n",
    "spots[X_COL] = pd.to_numeric(spots[X_COL], errors=\"coerce\")\n",
    "spots[Y_COL] = pd.to_numeric(spots[Y_COL], errors=\"coerce\")\n",
    "spots = spots.dropna(subset=[X_COL, Y_COL]).copy()\n",
    "\n",
    "# EPSG 후보를 넓게 돌려서 \"가장 많이 매핑되는\" 좌표계를 자동 선택\n",
    "epsg_candidates = [\"EPSG:5186\",\"EPSG:5181\",\"EPSG:5179\",\"EPSG:5187\",\"EPSG:5183\",\"EPSG:5174\",\"EPSG:5178\"]\n",
    "best = {\"epsg\": None, \"n\": -1, \"joined\": None}\n",
    "\n",
    "for epsg in epsg_candidates:\n",
    "    g_spots = gpd.GeoDataFrame(\n",
    "        spots[[SPOT_COL, X_COL, Y_COL]].copy(),\n",
    "        geometry=gpd.points_from_xy(spots[X_COL], spots[Y_COL]),\n",
    "        crs=epsg\n",
    "    ).to_crs(grid.crs)\n",
    "\n",
    "    joined = gpd.sjoin(g_spots, grid[[\"grid_id\",\"geometry\"]], how=\"inner\", predicate=\"within\")\n",
    "    n = len(joined)\n",
    "    print(epsg, \"joined_rows=\", n)\n",
    "    if n > best[\"n\"]:\n",
    "        best = {\"epsg\": epsg, \"n\": n, \"joined\": joined}\n",
    "\n",
    "print(\"\\n✅ BEST EPSG:\", best[\"epsg\"], \"| joined_rows:\", best[\"n\"])\n",
    "if best[\"n\"] <= 10:\n",
    "    raise RuntimeError(\"매핑이 너무 적게 됐어. 격자 CRS/spot 좌표가 서로 안 맞을 가능성이 큼. joined_rows가 최소 수백은 나와야 정상.\")\n",
    "\n",
    "spot_to_grid = best[\"joined\"][[SPOT_COL,\"grid_id\"]].drop_duplicates().copy()\n",
    "spot_to_grid.rename(columns={SPOT_COL:\"spot\"}, inplace=True)\n",
    "spot_to_grid[\"spot\"] = spot_to_grid[\"spot\"].astype(str)\n",
    "\n",
    "tmp = wide.merge(spot_to_grid, on=\"spot\", how=\"inner\")\n",
    "\n",
    "grid_day = tmp.groupby([\"grid_id\",\"yyyymmdd\"], as_index=False)[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].sum()\n",
    "grid_med = grid_day.groupby(\"grid_id\", as_index=False)[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].median()\n",
    "\n",
    "grid_med.to_csv(OUT_TRAFFIC, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\n✅ saved:\", OUT_TRAFFIC)\n",
    "print(\"grid_med rows:\", len(grid_med))\n",
    "print(\"nonzero grids:\", (grid_med[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].sum(axis=1) > 0).sum())\n",
    "grid_med.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da2930-e21c-4aaa-9fef-a95df77155db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid.crs(original): EPSG:4326\n",
      "grid bounds: [127.02822996  37.52908006 127.06787684  37.55387744]\n",
      "spot x/y range: (np.float64(181967.262021), np.float64(215469.587229)) (np.float64(437292.624732), np.float64(465841.155869))\n",
      "\n",
      "✅ BEST COMBO\n",
      "grid_crs: EPSG:4326\n",
      "spot_crs: EPSG:5181\n",
      "joined rows: 2\n",
      "unique spots mapped: 2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "매핑된 spot이 너무 적어(20 미만). 격자 파일이 성수 격자가 아니거나, 좌표가 다른 체계일 가능성이 커.\ngrid bounds/spot range 출력값 캡쳐해서 보여주면 바로 맞춰줄 수 있어.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33munique spots mapped:\u001b[39m\u001b[33m\"\u001b[39m, best[\u001b[33m\"\u001b[39m\u001b[33mn_spots\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best[\u001b[33m\"\u001b[39m\u001b[33mn_spots\u001b[39m\u001b[33m\"\u001b[39m] < \u001b[32m20\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     84\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m매핑된 spot이 너무 적어(20 미만). 격자 파일이 성수 격자가 아니거나, 좌표가 다른 체계일 가능성이 커.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     85\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgrid bounds/spot range 출력값 캡쳐해서 보여주면 바로 맞춰줄 수 있어.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m     )\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# 3) raw -> spot-day wide(3칼럼)\u001b[39;00m\n\u001b[32m     89\u001b[39m raw = pd.read_csv(RAW_MULTI)\n",
      "\u001b[31mRuntimeError\u001b[39m: 매핑된 spot이 너무 적어(20 미만). 격자 파일이 성수 격자가 아니거나, 좌표가 다른 체계일 가능성이 커.\ngrid bounds/spot range 출력값 캡쳐해서 보여주면 바로 맞춰줄 수 있어."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "PRO_DIR = ROOT / \"data\" / \"processed\"\n",
    "RAW_DIR = ROOT / \"data\" / \"raw\" / \"traffic\"\n",
    "\n",
    "GRID_PATH = PRO_DIR / \"seongsu_grid_250m_enriched.geojson\"\n",
    "RAW_MULTI = RAW_DIR / \"volinfo_hourly_raw_20251201_1214.csv\"\n",
    "SPOTINFO  = RAW_DIR / \"spotinfo.csv\"\n",
    "\n",
    "OUT_TRAFFIC = PRO_DIR / \"seongsu_grid_traffic_3cols_median_20251201_1214.csv\"\n",
    "\n",
    "# 로드 (절대 grid CRS를 임의로 set 하지 말고 원본 그대로 할 것)\n",
    "grid0 = gpd.read_file(GRID_PATH)\n",
    "grid0.columns = [c.lower() for c in grid0.columns]\n",
    "if \"grid_id\" not in grid0.columns:\n",
    "    raise KeyError(f\"grid_id 없음. grid cols={list(grid0.columns)}\")\n",
    "\n",
    "spots = pd.read_csv(SPOTINFO)\n",
    "spots.columns = [c.lower() for c in spots.columns]\n",
    "SPOT_COL = \"spot_num\"\n",
    "X_COL = \"grs80tm_x\"\n",
    "Y_COL = \"grs80tm_y\"\n",
    "\n",
    "spots[SPOT_COL] = spots[SPOT_COL].astype(str)\n",
    "spots[X_COL] = pd.to_numeric(spots[X_COL], errors=\"coerce\")\n",
    "spots[Y_COL] = pd.to_numeric(spots[Y_COL], errors=\"coerce\")\n",
    "spots = spots.dropna(subset=[X_COL, Y_COL]).copy()\n",
    "\n",
    "print(\"grid.crs(original):\", grid0.crs)\n",
    "print(\"grid bounds:\", grid0.total_bounds)  # [minx, miny, maxx, maxy]\n",
    "print(\"spot x/y range:\", (spots[X_COL].min(), spots[X_COL].max()), (spots[Y_COL].min(), spots[Y_COL].max()))\n",
    "\n",
    "# 후보 CRS 세트\n",
    "# grid CRS가 파일에 있으면 그걸 우선 사용, 없으면 후보를 넓게 탐색\n",
    "if grid0.crs is not None:\n",
    "    grid_crs_candidates = [grid0.crs.to_string()]\n",
    "else:\n",
    "    # geojson인데도 CRS 누락되는 경우 많아서 광범위 후보\n",
    "    grid_crs_candidates = [\"EPSG:4326\", \"EPSG:5179\", \"EPSG:5186\", \"EPSG:5181\", \"EPSG:5187\", \"EPSG:5183\", \"EPSG:3857\"]\n",
    "\n",
    "# SpotInfo 좌표는 TM 계열일 확률 높아서 후보 여러 개\n",
    "spot_crs_candidates = [\"EPSG:5186\",\"EPSG:5181\",\"EPSG:5179\",\"EPSG:5187\",\"EPSG:5183\",\"EPSG:5174\",\"EPSG:5178\",\"EPSG:3857\",\"EPSG:4326\"]\n",
    "\n",
    "best = {\"grid_crs\": None, \"spot_crs\": None, \"joined\": None, \"n_rows\": -1, \"n_spots\": -1}\n",
    "\n",
    "# grid CRS × spot CRS 조합 탐색\n",
    "for gcrs in grid_crs_candidates:\n",
    "    grid = grid0.copy()\n",
    "    # grid 좌표 자체를 \"변환\"하면 망할 수 있어서: CRS만 가정해서 박아넣고(allow_override), 좌표는 그대로 둠\n",
    "    grid = grid.set_crs(gcrs, allow_override=True)\n",
    "\n",
    "    for scrs in spot_crs_candidates:\n",
    "        g_spots = gpd.GeoDataFrame(\n",
    "            spots[[SPOT_COL, X_COL, Y_COL]].copy(),\n",
    "            geometry=gpd.points_from_xy(spots[X_COL], spots[Y_COL]),\n",
    "            crs=scrs\n",
    "        )\n",
    "        try:\n",
    "            g_spots2 = g_spots.to_crs(gcrs)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            joined = gpd.sjoin(g_spots2, grid[[\"grid_id\",\"geometry\"]], how=\"inner\", predicate=\"within\")\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        n_rows = len(joined)\n",
    "        n_spots = joined[SPOT_COL].nunique() if n_rows else 0\n",
    "\n",
    "        if (n_spots > best[\"n_spots\"]) or (n_spots == best[\"n_spots\"] and n_rows > best[\"n_rows\"]):\n",
    "            best = {\"grid_crs\": gcrs, \"spot_crs\": scrs, \"joined\": joined, \"n_rows\": n_rows, \"n_spots\": n_spots}\n",
    "\n",
    "print(\"\\n✅ BEST COMBO\")\n",
    "print(\"grid_crs:\", best[\"grid_crs\"])\n",
    "print(\"spot_crs:\", best[\"spot_crs\"])\n",
    "print(\"joined rows:\", best[\"n_rows\"])\n",
    "print(\"unique spots mapped:\", best[\"n_spots\"])\n",
    "\n",
    "if best[\"n_spots\"] < 20:\n",
    "    raise RuntimeError(\n",
    "        \"매핑된 spot이 너무 적어(20 미만). 격자 파일이 성수 격자가 아니거나, 좌표가 다른 체계일 가능성이 커.\\n\"\n",
    "        \"grid bounds/spot range 출력값 캡쳐해서 보여주면 바로 맞춰줄 수 있어.\"\n",
    "    )\n",
    "\n",
    "# raw -> spot-day wide(3칼럼)\n",
    "raw = pd.read_csv(RAW_MULTI)\n",
    "raw.columns = [c.lower() for c in raw.columns]\n",
    "vol_candidates = [c for c in raw.columns if c in [\"vol\",\"volume\",\"traffic\",\"trfvlm\",\"traffic_volume\"]]\n",
    "if not vol_candidates:\n",
    "    raise KeyError(f\"교통량 값 컬럼 못 찾음. raw cols={list(raw.columns)}\")\n",
    "VOL_COL = vol_candidates[0]\n",
    "\n",
    "raw[VOL_COL] = pd.to_numeric(raw[VOL_COL], errors=\"coerce\").fillna(0)\n",
    "raw[\"spot\"] = raw[\"spot\"].astype(str)\n",
    "raw[\"hh\"] = raw[\"hh\"].astype(str).str.zfill(2)\n",
    "\n",
    "spot_day_hh = raw.groupby([\"spot\",\"yyyymmdd\",\"hh\"], as_index=False)[VOL_COL].sum()\n",
    "wide = spot_day_hh.pivot(index=[\"spot\",\"yyyymmdd\"], columns=\"hh\", values=VOL_COL).fillna(0).reset_index()\n",
    "\n",
    "rename_map = {\"01\":\"traffic_01_02\",\"02\":\"traffic_02_03\",\"03\":\"traffic_03_04\"}\n",
    "for hh, newc in rename_map.items():\n",
    "    if hh in wide.columns:\n",
    "        wide.rename(columns={hh:newc}, inplace=True)\n",
    "    else:\n",
    "        wide[newc] = 0\n",
    "\n",
    "wide = wide[[\"spot\",\"yyyymmdd\",\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].copy()\n",
    "\n",
    "# spot->grid 매핑 (best 조합 사용)\n",
    "joined = best[\"joined\"]\n",
    "spot_to_grid = joined[[SPOT_COL, \"grid_id\"]].drop_duplicates().copy()\n",
    "spot_to_grid.rename(columns={SPOT_COL:\"spot\"}, inplace=True)\n",
    "spot_to_grid[\"spot\"] = spot_to_grid[\"spot\"].astype(str)\n",
    "\n",
    "tmp = wide.merge(spot_to_grid, on=\"spot\", how=\"inner\")\n",
    "grid_day = tmp.groupby([\"grid_id\",\"yyyymmdd\"], as_index=False)[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].sum()\n",
    "grid_med = grid_day.groupby(\"grid_id\", as_index=False)[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].median()\n",
    "\n",
    "grid_med.to_csv(OUT_TRAFFIC, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\n✅ saved:\", OUT_TRAFFIC)\n",
    "print(\"grid_med rows:\", len(grid_med))\n",
    "print(\"nonzero grids:\", (grid_med[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].sum(axis=1) > 0).sum())\n",
    "grid_med.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd4a2ba3-04e5-4426-909d-9b87d84dccc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spot_med rows: 137\n",
      "✅ spot_med nonzero: 136\n",
      "✅ saved traffic: C:\\Users\\A\\OneDrive\\바탕 화면\\seoul-dimming-system\\data\\processed\\seongsu_grid_traffic_3cols_median_20251201_1214_NEAREST.csv | rows: 109\n",
      "✅ saved geojson: C:\\Users\\A\\OneDrive\\바탕 화면\\seoul-dimming-system\\data\\processed\\seongsu_grid_250m_plus_traffic_3cols_median_20251201_1214_NEAREST.geojson\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>traffic_01_02</th>\n",
       "      <th>traffic_02_03</th>\n",
       "      <th>traffic_03_04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>752.5</td>\n",
       "      <td>589.0</td>\n",
       "      <td>449.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>752.5</td>\n",
       "      <td>589.0</td>\n",
       "      <td>449.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>752.5</td>\n",
       "      <td>589.0</td>\n",
       "      <td>449.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_id  traffic_01_02  traffic_02_03  traffic_03_04\n",
       "0        0         2808.0         2278.0         1958.0\n",
       "1        1         2808.0         2278.0         1958.0\n",
       "2        2          752.5          589.0          449.5\n",
       "3        3          752.5          589.0          449.5\n",
       "4        4         2808.0         2278.0         1958.0\n",
       "5        5         2808.0         2278.0         1958.0\n",
       "6        6         2808.0         2278.0         1958.0\n",
       "7        7         2808.0         2278.0         1958.0\n",
       "8        8         2808.0         2278.0         1958.0\n",
       "9        9          752.5          589.0          449.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "PRO_DIR = ROOT / \"data\" / \"processed\"\n",
    "RAW_DIR = ROOT / \"data\" / \"raw\" / \"traffic\"\n",
    "\n",
    "GRID_PATH = PRO_DIR / \"seongsu_grid_250m_enriched.geojson\"\n",
    "RAW_MULTI = RAW_DIR / \"volinfo_hourly_raw_20251201_1214.csv\"\n",
    "SPOTINFO  = RAW_DIR / \"spotinfo.csv\"\n",
    "\n",
    "OUT_TRAFFIC = PRO_DIR / \"seongsu_grid_traffic_3cols_median_20251201_1214_NEAREST.csv\"\n",
    "OUT_GEOJSON = PRO_DIR / \"seongsu_grid_250m_plus_traffic_3cols_median_20251201_1214_NEAREST.geojson\"\n",
    "\n",
    "# 1) grid (4326)\n",
    "grid = gpd.read_file(GRID_PATH)\n",
    "grid.columns = [c.lower() for c in grid.columns]\n",
    "if grid.crs is None:\n",
    "    grid = grid.set_crs(\"EPSG:4326\", allow_override=True)\n",
    "GRID_CRS = grid.crs.to_string()\n",
    "assert GRID_CRS.upper() == \"EPSG:4326\"\n",
    "\n",
    "# 2) raw -> spot-day wide -> spot별 14일 median (3칼럼)\n",
    "raw = pd.read_csv(RAW_MULTI)\n",
    "raw.columns = [c.lower() for c in raw.columns]\n",
    "\n",
    "vol_candidates = [c for c in raw.columns if c in [\"vol\",\"volume\",\"traffic\",\"trfvlm\",\"traffic_volume\"]]\n",
    "if not vol_candidates:\n",
    "    raise KeyError(f\"교통량 값 컬럼 못 찾음. raw cols={list(raw.columns)}\")\n",
    "VOL_COL = vol_candidates[0]\n",
    "\n",
    "raw[VOL_COL] = pd.to_numeric(raw[VOL_COL], errors=\"coerce\").fillna(0)\n",
    "raw[\"spot\"] = raw[\"spot\"].astype(str)\n",
    "raw[\"hh\"] = raw[\"hh\"].astype(str).str.zfill(2)\n",
    "\n",
    "spot_day_hh = raw.groupby([\"spot\",\"yyyymmdd\",\"hh\"], as_index=False)[VOL_COL].sum()\n",
    "wide = spot_day_hh.pivot(index=[\"spot\",\"yyyymmdd\"], columns=\"hh\", values=VOL_COL).fillna(0).reset_index()\n",
    "\n",
    "rename_map = {\"01\":\"traffic_01_02\",\"02\":\"traffic_02_03\",\"03\":\"traffic_03_04\"}\n",
    "for hh, newc in rename_map.items():\n",
    "    if hh in wide.columns:\n",
    "        wide.rename(columns={hh:newc}, inplace=True)\n",
    "    else:\n",
    "        wide[newc] = 0\n",
    "\n",
    "wide = wide[[\"spot\",\"yyyymmdd\",\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].copy()\n",
    "\n",
    "spot_med = (\n",
    "    wide.groupby(\"spot\", as_index=False)[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]]\n",
    "        .median()\n",
    ")\n",
    "\n",
    "print(\"✅ spot_med rows:\", len(spot_med))\n",
    "print(\"✅ spot_med nonzero:\", (spot_med[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].sum(axis=1) > 0).sum())\n",
    "\n",
    "# 3) SpotInfo(TM) -> geometry 만들기 (spot CRS는 우선 EPSG:5186로 가정)\n",
    "spots = pd.read_csv(SPOTINFO)\n",
    "spots.columns = [c.lower() for c in spots.columns]\n",
    "\n",
    "SPOT_COL = \"spot_num\"\n",
    "X_COL = \"grs80tm_x\"\n",
    "Y_COL = \"grs80tm_y\"\n",
    "\n",
    "spots[SPOT_COL] = spots[SPOT_COL].astype(str)\n",
    "spots[X_COL] = pd.to_numeric(spots[X_COL], errors=\"coerce\")\n",
    "spots[Y_COL] = pd.to_numeric(spots[Y_COL], errors=\"coerce\")\n",
    "spots = spots.dropna(subset=[X_COL, Y_COL]).copy()\n",
    "\n",
    "g_spots = gpd.GeoDataFrame(\n",
    "    spots[[SPOT_COL, X_COL, Y_COL]].copy(),\n",
    "    geometry=gpd.points_from_xy(spots[X_COL], spots[Y_COL]),\n",
    "    crs=\"EPSG:5181\"   # ← 숫자대(18만/43만)가 여기랑 잘 맞음\n",
    ").to_crs(\"EPSG:5181\")\n",
    "\n",
    "# spot_med 붙이기\n",
    "g_spots = g_spots.rename(columns={SPOT_COL:\"spot\"})\n",
    "g_spots[\"spot\"] = g_spots[\"spot\"].astype(str)\n",
    "g_spots = g_spots.merge(spot_med, on=\"spot\", how=\"left\")\n",
    "for c in [\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]:\n",
    "    g_spots[c] = g_spots[c].fillna(0)\n",
    "\n",
    "# 4) grid centroid 만들고 (거리 계산은 미터계가 좋아서 5186으로 변환)\n",
    "g_grid_m = grid.to_crs(\"EPSG:5181\").copy()\n",
    "cent = g_grid_m.copy()\n",
    "cent[\"geometry\"] = g_grid_m.geometry.centroid\n",
    "\n",
    "# 5) centroid -> 가장 가까운 spot 붙이기\n",
    "# max_distance는 넉넉하게(예: 5000m). 너무 멀면 None 나올 수 있어서 0으로 채움.\n",
    "joined = gpd.sjoin_nearest(\n",
    "    cent[[\"grid_id\",\"geometry\"]],\n",
    "    g_spots[[\"spot\",\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\",\"geometry\"]],\n",
    "    how=\"left\",\n",
    "    distance_col=\"dist_m\",\n",
    ")\n",
    "\n",
    "grid_traffic = joined[[\"grid_id\",\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\",\"dist_m\"]].copy()\n",
    "for c in [\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]:\n",
    "    grid_traffic[c] = grid_traffic[c].fillna(0)\n",
    "\n",
    "grid_traffic.to_csv(OUT_TRAFFIC, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ saved traffic:\", OUT_TRAFFIC, \"| rows:\", len(grid_traffic))\n",
    "\n",
    "# 6) geojson에도 붙여서 저장(원래 4326 grid에 join)\n",
    "grid2 = grid.merge(grid_traffic.drop(columns=[\"dist_m\"]), on=\"grid_id\", how=\"left\")\n",
    "for c in [\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]:\n",
    "    grid2[c] = grid2[c].fillna(0)\n",
    "\n",
    "grid2.to_file(OUT_GEOJSON, driver=\"GeoJSON\", encoding=\"utf-8\")\n",
    "print(\"✅ saved geojson:\", OUT_GEOJSON)\n",
    "\n",
    "grid2[[\"grid_id\",\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab60d3d0-23d0-4220-85c0-8d2b9287dbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ base rows: 109\n",
      "✅ merged rows: 109\n",
      "✅ nonzero grids: 109 / 109\n",
      "✅ saved: C:\\Users\\A\\OneDrive\\바탕 화면\\seoul-dimming-system\\data\\processed\\grid_features_base_plus_traffic3cols_20251201_1214_NEAREST.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>traffic_01_02</th>\n",
       "      <th>traffic_02_03</th>\n",
       "      <th>traffic_03_04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>752.5</td>\n",
       "      <td>589.0</td>\n",
       "      <td>449.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>752.5</td>\n",
       "      <td>589.0</td>\n",
       "      <td>449.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>1958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>752.5</td>\n",
       "      <td>589.0</td>\n",
       "      <td>449.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  grid_id  traffic_01_02  traffic_02_03  traffic_03_04\n",
       "0       0         2808.0         2278.0         1958.0\n",
       "1       1         2808.0         2278.0         1958.0\n",
       "2       2          752.5          589.0          449.5\n",
       "3       3          752.5          589.0          449.5\n",
       "4       4         2808.0         2278.0         1958.0\n",
       "5       5         2808.0         2278.0         1958.0\n",
       "6       6         2808.0         2278.0         1958.0\n",
       "7       7         2808.0         2278.0         1958.0\n",
       "8       8         2808.0         2278.0         1958.0\n",
       "9       9          752.5          589.0          449.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PRO_DIR = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "BASE_FEATURES = PRO_DIR / \"grid_features_base.csv\"\n",
    "TRAFFIC_3COLS = PRO_DIR / \"seongsu_grid_traffic_3cols_median_20251201_1214_NEAREST.csv\"\n",
    "OUT_FINAL     = PRO_DIR / \"grid_features_base_plus_traffic3cols_20251201_1214_NEAREST.csv\"\n",
    "\n",
    "base = pd.read_csv(BASE_FEATURES, dtype={\"grid_id\": str})\n",
    "traffic = pd.read_csv(TRAFFIC_3COLS, dtype={\"grid_id\": str})\n",
    "\n",
    "# grid_id 컬럼명 통일\n",
    "base.columns = [c if c.lower() != \"grid_id\" else \"grid_id\" for c in base.columns]\n",
    "traffic.columns = [c if c.lower() != \"grid_id\" else \"grid_id\" for c in traffic.columns]\n",
    "\n",
    "merged = base.merge(\n",
    "    traffic[[\"grid_id\",\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]],\n",
    "    on=\"grid_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "for c in [\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]:\n",
    "    merged[c] = merged[c].fillna(0)\n",
    "\n",
    "merged.to_csv(OUT_FINAL, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ base rows:\", len(base))\n",
    "print(\"✅ merged rows:\", len(merged))\n",
    "print(\"✅ nonzero grids:\", (merged[[\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].sum(axis=1) > 0).sum(), \"/\", len(merged))\n",
    "print(\"✅ saved:\", OUT_FINAL)\n",
    "\n",
    "merged[[\"grid_id\",\"traffic_01_02\",\"traffic_02_03\",\"traffic_03_04\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4545b142-744e-4d97-9450-b8f604b854fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
